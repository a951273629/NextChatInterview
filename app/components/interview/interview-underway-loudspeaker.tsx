import React, { useRef, useState, useEffect } from "react";
import StopIcon from "@/app/icons/pause.svg";
import styles from "./interview-underway-loudspeaker.module.scss";
import clsx from "clsx";
import {
  AzureSpeechRecognizer,
  getAzureSpeechConfig,
  isAzureSpeechAvailable,
} from "@/app/components/interview/azureSpeech";
import { SyncMode, LLMResponseData } from "@/app/types/websocket-sync";
import { nanoid } from "nanoid";

// æ¶ˆæ¯ç±»å‹æ¥å£
interface Message {
  id: string;
  text: string;
  timestamp: number;
}



interface InterviewUnderwayLoudspeakerProps {
  // æ§åˆ¶çŠ¶æ€
  visible: boolean;
  recognitionLanguage: string;

  // å›è°ƒå‡½æ•°
  onTextUpdate: (text: string) => void;
  submitMessage: (text: string) => void;
  onStop: () => void;

  // å¯é€‰ï¼šé»˜è®¤è‡ªåŠ¨æäº¤çŠ¶æ€ï¼ˆæ‰¬å£°å™¨æ¨¡å¼ä¸‹é»˜è®¤å¼€å¯ï¼‰
  defaultAutoSubmit?: boolean;

  // åª’ä½“æµç›¸å…³props
  mediaStream: MediaStream | null;
  onRequestPermission: () => Promise<void>;

  // ç§»åŠ¨ç«¯ç›¸å…³
  onMinimize?: () => void;
  isMobile?: boolean;

  // æ¶ˆæ¯ç®¡ç†
  messages?: Message[];
  onAddMessage?: (text: string) => void;

  // æ˜¯å¦çª„å±
  shouldNarrow: boolean;

  // WebSocketç›¸å…³ï¼ˆæ¥æ”¶ç«¯ç”¨ï¼‰
  // onLLMResponse?: (data: LLMResponseData) => void;              // æ–°å¢LLMå›ç­”æ¥æ”¶å›è°ƒ
  syncEnabled?: boolean;
  syncMode?: SyncMode;
}

export const InterviewUnderwayLoudspeaker: React.FC<
  InterviewUnderwayLoudspeakerProps
> = ({
  visible,
  recognitionLanguage,
  onTextUpdate,
  submitMessage,
  onStop,
  defaultAutoSubmit = false,
  mediaStream,
  onRequestPermission,
  onMinimize,
  isMobile = false,
  messages = [],
  onAddMessage,
  shouldNarrow,
  // WebSocketå›è°ƒpropsï¼ˆæ¥æ”¶ç«¯ç”¨ï¼‰
  syncEnabled = false,
  syncMode = SyncMode.SENDER,
}) => {
  // è¯­éŸ³è¯†åˆ«ç›¸å…³çŠ¶æ€
  const [transcript, setTranscript] = useState("");
  const [listening, setListening] = useState(false);
  const [browserSupportsApi, setBrowserSupportsApi] = useState(true);
  const [audioAvailable, setAudioAvailable] = useState(false);
  const transcriptRef = useRef(transcript);

  // Azure Speech è¯†åˆ«å™¨å¼•ç”¨
  const azureSpeechRecognizerRef = useRef<AzureSpeechRecognizer | null>(null);

  // æ§åˆ¶çŠ¶æ€
  const [isPaused, setIsPaused] = useState(false);
  const [isAutoSubmit, setIsAutoSubmit] = useState(defaultAutoSubmit);
  const isAutoSubmitRef = useRef(isAutoSubmit);

  const [showTooltip, setShowTooltip] = useState(true);

  // æµ‹è¯•éŸ³é¢‘æ’­æ”¾ç›¸å…³çŠ¶æ€
  const [isPlayingTestAudio, setIsPlayingTestAudio] = useState(false);
  const testAudioRef = useRef<HTMLAudioElement>(null);

  const messagesEndRef = useRef<HTMLDivElement>(null);
  const lastSubmittedTextRef = useRef("");

  // ğŸ¯ å»¶è¿Ÿå¤„ç†æœºåˆ¶ï¼šåŒé‡ä¿é™©é˜²æ­¢æ–­å¥è¿‡å¿«
  const finalTextDelayTimerRef = useRef<NodeJS.Timeout | null>(null);
  const pendingFinalTextRef = useRef<string>("");
  // ğŸ¯ è·Ÿè¸ªå½“å‰å»¶è¿Ÿå‘¨æœŸå†…å·²å¤„ç†çš„æ–‡æœ¬ç‰‡æ®µï¼Œé¿å…é‡å¤æ‹¼æ¥
  const pendingTextSegmentsRef = useRef<Set<string>>(new Set());

  // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
  useEffect(() => {
    const checkBrowserSupport = async () => {
      const hasGetDisplayMedia = !!(
        navigator.mediaDevices && navigator.mediaDevices.getDisplayMedia
      );
      const hasAudioContext = !!(
        window.AudioContext || window.webkitAudioContext
      );
      const hasAzureSpeech = await isAzureSpeechAvailable();

      setBrowserSupportsApi(
        hasGetDisplayMedia && hasAudioContext && hasAzureSpeech,
      );

      if (!hasAzureSpeech) {
        console.warn("Azure Speech SDK ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®");
      }
    };

    checkBrowserSupport();
  }, []);

  // åˆå§‹åŒ– Azure Speech è¯†åˆ«å™¨
  const initializeAzureSpeechRecognizer = async () => {
    try {
      if (!mediaStream) {
        throw new Error("MediaStream æœªå‡†å¤‡å°±ç»ª");
      }

      console.log("ğŸ”§ å‡†å¤‡åˆå§‹åŒ– Azure Speech è¯†åˆ«å™¨...");
      const config = await getAzureSpeechConfig();
      // æ ¹æ®è¯†åˆ«è¯­è¨€è®¾ç½®é…ç½®
      config.language = recognitionLanguage;

      const recognizer = new AzureSpeechRecognizer(config);

      // è®¾ç½®éŸ³é¢‘æµï¼ˆç°åœ¨æ˜¯åŒæ­¥æ–¹æ³•ï¼‰
      recognizer.createAudioConfigFromStream(mediaStream);

      azureSpeechRecognizerRef.current = recognizer;

      return recognizer;
    } catch (error) {
      console.error("âŒ åˆå§‹åŒ– Azure Speech è¯†åˆ«å™¨å¤±è´¥:", error);
      throw error;
    }
  };

  // å¼€å§‹è¯­éŸ³è¯†åˆ« Azure Speech SDK
  const startSpeechRecognition = async () => {
    if (!mediaStream) {
      console.log("âš ï¸ åª’ä½“æµæœªå‡†å¤‡å°±ç»ªï¼Œè¯·å…ˆè·å–å½•å±æƒé™");
      return;
    }

    try {
      // console.log("ğŸš€ å¼€å§‹ Azure è¯­éŸ³è¯†åˆ«...");

      // åˆå§‹åŒ– Azure Speech è¯†åˆ«å™¨
      const recognizer = await initializeAzureSpeechRecognizer();

      // å¼€å§‹è¿ç»­è¯†åˆ«
      recognizer.startContinuousRecognition(
        // è¯†åˆ«ç»“æœå›è°ƒ
        (text: string, isFinal: boolean) => {
          console.log(
            // `ğŸ¯ Azure è¯†åˆ«ç»“æœ (${isFinal ? "âœ…æœ€ç»ˆ" : "ğŸ”„ä¸­é—´"}):`,
            text,
          );

          // ğŸ¯ æ ¸å¿ƒæ”¹è¿›ï¼šä»»ä½•æœ‰å†…å®¹çš„è¯†åˆ«éƒ½ä¼šåˆ·æ–°å»¶è¿Ÿå®šæ—¶å™¨
          if (text.trim() !== "") {
            const trimmedText = text.trim();
            // console.log(`ğŸ™ï¸ æ£€æµ‹åˆ°è¯­éŸ³å†…å®¹ (${isFinal ? "âœ…æœ€ç»ˆ" : "ğŸ”„è¿›è¡Œä¸­"}):`, trimmedText);
            
            // ğŸ¯ å»¶è¿Ÿå®šæ—¶å™¨åˆ·æ–°é€»è¾‘ï¼šä»»ä½•æœ‰å†…å®¹çš„è¯†åˆ«éƒ½åˆ·æ–°
            // æ¸…é™¤ä¹‹å‰çš„å®šæ—¶å™¨ï¼ˆå¦‚æœæœ‰ï¼‰
            if (finalTextDelayTimerRef.current) {
              clearTimeout(finalTextDelayTimerRef.current);
              // console.log("â±ï¸ åˆ·æ–°å»¶è¿Ÿå®šæ—¶å™¨ - æ£€æµ‹åˆ°æ–°çš„è¯­éŸ³æ´»åŠ¨");
            }
            
            // ğŸ¯ æ–‡æœ¬æ‹¼æ¥é€»è¾‘ï¼šåªæœ‰æœ€ç»ˆç»“æœæ‰è¿›è¡Œæ‹¼æ¥
            if (isFinal) {
              // é¿å…é‡å¤å¤„ç†ç›¸åŒçš„æ–‡æœ¬ç‰‡æ®µ
              if (!pendingTextSegmentsRef.current.has(trimmedText)) {
                // console.log("ğŸ“ å¤„ç†æœ€ç»ˆè¯­éŸ³ç‰‡æ®µ:", trimmedText);
                
                // æ‹¼æ¥æ–°æ–‡æœ¬åˆ°å¾…å¤„ç†æ–‡æœ¬ä¸­ï¼Œè€Œéæ›¿æ¢
                if (pendingFinalTextRef.current) {
                  pendingFinalTextRef.current += " " + trimmedText;
                  // console.log("ğŸ”— æ‹¼æ¥æ–‡æœ¬:", pendingFinalTextRef.current);
                } else {
                  pendingFinalTextRef.current = trimmedText;
                  // console.log("ğŸ“ é¦–æ¬¡è®¾ç½®æ–‡æœ¬:", pendingFinalTextRef.current);
                }
                
                // è®°å½•å·²å¤„ç†çš„æ–‡æœ¬ç‰‡æ®µï¼Œé¿å…é‡å¤æ‹¼æ¥
                pendingTextSegmentsRef.current.add(trimmedText);
              }
            }
            
            // ğŸ¯ é‡æ–°è®¾ç½®å»¶è¿Ÿå¤„ç†å®šæ—¶å™¨ï¼ˆä¸ç®¡æ˜¯interimè¿˜æ˜¯finaléƒ½ä¼šåˆ·æ–°ï¼‰
            finalTextDelayTimerRef.current = setTimeout(() => {
              const finalText = pendingFinalTextRef.current;
              if (finalText && finalText !== lastSubmittedTextRef.current) {
                // console.log("âœ… å»¶è¿Ÿ3ç§’åå¤„ç†æ‹¼æ¥çš„è¯­éŸ³ç»“æœ:", finalText);
                
                onAddMessage?.(finalText);
                lastSubmittedTextRef.current = finalText;
                resetTranscript();

                // è‡ªåŠ¨æäº¤é€»è¾‘ï¼šè¯­éŸ³è¯†åˆ«ç»“æœæäº¤ç»™LLMï¼ŒLLMè¾“å‡ºä¼šé€šè¿‡chat.tsè‡ªåŠ¨å‘é€åˆ°WebSocket
                if (isAutoSubmitRef.current) {
                  console.log("ğŸš€ å»¶è¿Ÿå¤„ç†å®Œæˆï¼Œè‡ªåŠ¨æäº¤æ‹¼æ¥çš„è¯­éŸ³:", finalText,"isAutoSubmitRef.current",isAutoSubmitRef.current);
                  submitMessage(finalText);
                }
              }
              // æ¸…ç†å®šæ—¶å™¨å¼•ç”¨å’Œæ–‡æœ¬ç‰‡æ®µè®°å½•
              finalTextDelayTimerRef.current = null;
              pendingFinalTextRef.current = "";
              pendingTextSegmentsRef.current.clear();
              // console.log("ğŸ§¹ æ¸…ç†å»¶è¿Ÿå¤„ç†çŠ¶æ€");
            }, 1800); // 1800ç§’å»¶è¿Ÿ
          }
          
          // ğŸ¯ æ›´æ–°interimç»“æœæ˜¾ç¤ºï¼ˆä¸å½±å“å»¶è¿Ÿå¤„ç†é€»è¾‘ï¼‰
          if (!isFinal) {
            setTranscript(text);
            transcriptRef.current = text;
            onTextUpdate(text);
          }
        },
        // é”™è¯¯å›è°ƒ
        (error: string) => {
          console.error("âŒ Azure è¯­éŸ³è¯†åˆ«é”™è¯¯:", error);
          setListening(false);
          setAudioAvailable(false);
        },
        // ç»“æŸå›è°ƒ
        () => {
          console.log("ğŸ Azure è¯­éŸ³è¯†åˆ«ç»“æŸ");
          // å¦‚æœåº”è¯¥ç»§ç»­ç›‘å¬ä½†è¯†åˆ«ç»“æŸäº†ï¼Œé‡æ–°å¯åŠ¨
          if (visible && !isPaused && audioAvailable && mediaStream) {
            setTimeout(() => {
              console.log("ğŸ”„ é‡æ–°å¯åŠ¨è¯­éŸ³è¯†åˆ«...");
              startSpeechRecognition();
            }, 1000);
          } else {
            setListening(false);
          }
        },
      );

      setListening(true);
      setAudioAvailable(true);
    } catch (error: any) {
      console.error("âŒ å¯åŠ¨ Azure è¯­éŸ³è¯†åˆ«å¤±è´¥:", error);
      setAudioAvailable(false);
      setListening(false);
    }
  };

  // åœæ­¢è¯­éŸ³è¯†åˆ«
  const stopSpeechRecognition = () => {
    try {
      // åœæ­¢ Azure Speech è¯†åˆ«å™¨
      if (azureSpeechRecognizerRef.current) {
        azureSpeechRecognizerRef.current.stopRecognition();
        azureSpeechRecognizerRef.current.dispose();
        azureSpeechRecognizerRef.current = null;
      }

      // ğŸ¯ æ¸…ç†å»¶è¿Ÿå¤„ç†å®šæ—¶å™¨å’Œæ–‡æœ¬ç‰‡æ®µè®°å½•
      if (finalTextDelayTimerRef.current) {
        clearTimeout(finalTextDelayTimerRef.current);
        finalTextDelayTimerRef.current = null;
        console.log("â±ï¸ åœæ­¢è¯†åˆ«æ—¶æ¸…ç†å»¶è¿Ÿå®šæ—¶å™¨");
      }
      pendingFinalTextRef.current = "";
      pendingTextSegmentsRef.current.clear();

      setListening(false);
      setAudioAvailable(false);
    } catch (error) {
      console.error("åœæ­¢ Azure è¯­éŸ³è¯†åˆ«å¤±è´¥:", error);
    }
  };

  // é‡ç½®è½¬å½•æ–‡æœ¬
  const resetTranscript = () => {
    setTranscript("");
    transcriptRef.current = "";
    onTextUpdate("");
  };

  // å°†transcriptæ›´æ–°åˆ°çˆ¶ç»„ä»¶
  const lastTranscriptRef = useRef("");
  useEffect(() => {
    transcriptRef.current = transcript;
    
    // åªæœ‰åœ¨transcriptçœŸæ­£å˜åŒ–æ—¶æ‰è°ƒç”¨onTextUpdate
    if (transcript !== lastTranscriptRef.current) {
      lastTranscriptRef.current = transcript;
      onTextUpdate(transcript);
    }
  }, [transcript, onTextUpdate]);

  // æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  };

  // æ¯å½“æ¶ˆæ¯åˆ—è¡¨æ›´æ–°æ—¶ï¼Œæ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  // æ¶ˆæ¯ç‚¹å‡»å¤„ç†å‡½æ•°
  const handleMessageClick = (messageText: string) => {
    // console.log("æ¶ˆæ¯è¢«ç‚¹å‡»:", messageText);
    submitMessage(messageText);
    
    // åœ¨ç§»åŠ¨ç«¯æ¨¡å¼ä¸‹ï¼Œç‚¹å‡»æ¶ˆæ¯åæœ€å°åŒ–é¡µé¢
    if (isMobile && onMinimize) {
      onMinimize();
    }
  };

  // å½“ç»„ä»¶å¯è§ä¸”æœªæš‚åœæ—¶å¼€å§‹éŸ³é¢‘æ•è·
  useEffect(() => {
    if (visible && !isPaused && browserSupportsApi && mediaStream) {
      console.log("useEffect: å¼€å§‹è¯­éŸ³è¯†åˆ«");
      startSpeechRecognition();
    } else {
      console.log("useEffect: åœæ­¢è¯­éŸ³è¯†åˆ«");
      stopSpeechRecognition();
    }

    return () => {
      // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
      stopSpeechRecognition();
    };
  }, [visible, isPaused, browserSupportsApi, mediaStream]);

  // æš‚åœ/æ¢å¤åŠŸèƒ½
  const togglePauseCommit = () => {
    if (!isPaused) {
      stopSpeechRecognition();
      resetTranscript();
    } else {
      startSpeechRecognition();
      resetTranscript();
    }
    setIsPaused(!isPaused);
  };

  // åœæ­¢è¯†åˆ«
  const stopRecognition = () => {
    try {
      stopSpeechRecognition();
      onStop();
    } catch (error) {
      console.error("åœæ­¢ç³»ç»ŸéŸ³é¢‘æ•è·å¤±è´¥:", error);
    }
  };

  // æ’­æ”¾æµ‹è¯•éŸ³é¢‘
  const playTestAudio = () => {
    if (testAudioRef.current && !isPlayingTestAudio) {
      console.log("ğŸµ å¼€å§‹æ’­æ”¾æµ‹è¯•éŸ³é¢‘...");
      testAudioRef.current.currentTime = 0;
      testAudioRef.current.play()
        .then(() => {
          setIsPlayingTestAudio(true);
          console.log("ğŸµ æµ‹è¯•éŸ³é¢‘æ’­æ”¾å¼€å§‹");
        })
        .catch((error) => {
          console.error("âŒ æ’­æ”¾æµ‹è¯•éŸ³é¢‘å¤±è´¥:", error);
          setIsPlayingTestAudio(false);
        });
    }
  };

  // åœæ­¢æµ‹è¯•éŸ³é¢‘
  const stopTestAudio = () => {
    if (testAudioRef.current && isPlayingTestAudio) {
      console.log("â¸ï¸ åœæ­¢æ’­æ”¾æµ‹è¯•éŸ³é¢‘...");
      testAudioRef.current.pause();
      testAudioRef.current.currentTime = 0;
      setIsPlayingTestAudio(false);
    }
  };

  // å¤„ç†æµ‹è¯•éŸ³é¢‘æ’­æ”¾å®Œæˆ
  const handleTestAudioEnded = () => {
    console.log("ğŸ æµ‹è¯•éŸ³é¢‘æ’­æ”¾å®Œæˆ");
    setIsPlayingTestAudio(false);
  };

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      stopSpeechRecognition();
      
      // ğŸ¯ æ¸…ç†å»¶è¿Ÿå¤„ç†å®šæ—¶å™¨å’Œæ–‡æœ¬ç‰‡æ®µè®°å½•
      if (finalTextDelayTimerRef.current) {
        clearTimeout(finalTextDelayTimerRef.current);
        finalTextDelayTimerRef.current = null;
        console.log("â±ï¸ ç»„ä»¶å¸è½½æ—¶æ¸…ç†å»¶è¿Ÿå®šæ—¶å™¨");
      }
      pendingFinalTextRef.current = "";
      pendingTextSegmentsRef.current.clear();
      
      // æ¸…ç†æµ‹è¯•éŸ³é¢‘
      if (testAudioRef.current) {
        testAudioRef.current.pause();
        testAudioRef.current.currentTime = 0;
      }
    };
  }, []);

  return (
    <div
      className={clsx({
        [styles["narrow-mode"]]: shouldNarrow,
      })}
    >
      {/* è¯­éŸ³è¯†åˆ«çŠ¶æ€æŒ‡ç¤ºå™¨ */}
      <div className={styles.statusIndicator}>
        <div
          className={`${styles.indicatorDot} ${
            (syncEnabled && syncMode === SyncMode.RECEIVER) || listening
              ? styles.listening
              : styles.notListening
          }`}
        />
        <span className={styles.statusText}>
          {syncEnabled && syncMode === SyncMode.RECEIVER
            ? "æ¥æ”¶ä¸­"
            : listening
            ? "æ­£åœ¨ç›‘å¬æ‰¬å£°å™¨..."
            : isPaused
            ? "å·²æš‚åœ"
            : "æœªç›‘å¬"}
        </span>

        {/* æ·»åŠ å¯ç‚¹å‡»æç¤ºæ°”æ³¡ */}
        {showTooltip && (
          <div className={styles.clickableTooltip}>
            <div className={styles.tooltipContent}>å•å‡»ä¸‹é¢çš„æ¶ˆæ¯è·å–å›ç­”</div>
            <button
              className={styles.tooltipCloseBtn}
              onClick={() => setShowTooltip(false)}
            >
              âœ•
            </button>
          </div>
        )}
      </div>

      {/* é”™è¯¯æç¤º */}
      {(!browserSupportsApi ||
        (!mediaStream && !audioAvailable && syncMode === SyncMode.SENDER)) && (
        <div className={styles.errorMessage}>
          {!browserSupportsApi ? (
            "æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒç³»ç»ŸéŸ³é¢‘æ•è·åŠŸèƒ½æˆ– Azure Speech SDK é…ç½®ç¼ºå¤±ï¼Œè¯·ä½¿ç”¨Chromeæµè§ˆå™¨å¹¶é…ç½® Azure å¯†é’¥"
          ) : !mediaStream ? (
            <div className={styles.permissionRequest}>
              <div>æœªè·å–å½•å±æƒé™ï¼Œæ— æ³•ç›‘å¬ç³»ç»ŸéŸ³é¢‘</div>
              <button
                className={styles.requestButton}
                onClick={onRequestPermission}
              >
                è·å–å½•å±æƒé™
              </button>
            </div>
          ) : (
            "æ— æ³•è®¿é—®ç³»ç»ŸéŸ³é¢‘ï¼Œè¯·æ£€æŸ¥å±å¹•å…±äº«æƒé™"
          )}
        </div>
      )}

      {/* æ¶ˆæ¯å†å²è®°å½•åŒºåŸŸ */}
      <div className={styles.messagesContainer}>
        {messages.map((message) => (
          <div
            key={message.id}
            className={`${styles.message} ${styles.interviewerMessage}`}
            onClick={() => handleMessageClick(message.text)}
          >
            {message.text}
          </div>
        ))}
        <div ref={messagesEndRef} />
      </div>

      {/* å½“å‰è¯†åˆ«æ–‡æœ¬æ˜¾ç¤ºåŒºåŸŸ */}
      {transcript && transcript.trim() !== "" && (
        <div
          className={`${styles.transcriptDisplay} ${styles.interviewerText}`}
        >
          <div className={styles.transcriptLabel}>å½“å‰è¯†åˆ«:</div>
          {transcript}
        </div>
      )}

      {/* æŒ‰é’®åŒºåŸŸ */}
      <div className={styles.buttonContainer}>
        {/* æ·»åŠ è‡ªåŠ¨æäº¤çš„å¼€å…³ */}
        <div className={styles.settingItem}>
          <div className={styles.settingLabel}>è‡ªåŠ¨æäº¤ï¼š</div>
          <div className={styles.settingControl}>
            <label className={styles.switch}>
              <input
                type="checkbox"
                checked={isAutoSubmit}
                onChange={() => {
                  setIsAutoSubmit(!isAutoSubmit)
                  isAutoSubmitRef.current = !isAutoSubmit
                  console.log("isAutoSubmitRef.current:",isAutoSubmitRef.current);
                  
                }}
              />
              <span className={styles.slider}></span>
            </label>
            <span className={styles.settingStatus}>æ‰¬å£°å™¨æ¨¡å¼å¯ç”¨</span>
          </div>
        </div>

        {/* æµ‹è¯•éŸ³é¢‘æ’­æ”¾æŒ‰é’® */}
        <div className={styles.settingItem}>
          <div className={styles.settingLabel}>éŸ³é¢‘æµ‹è¯•ï¼š</div>
          <div className={styles.settingControl}>
            <button
              onClick={isPlayingTestAudio ? stopTestAudio : playTestAudio}
              className={`${styles.button} ${isPlayingTestAudio ? styles.pauseButton : styles.playButton}`}
              disabled={!visible}
            >
              <span>{isPlayingTestAudio ? "â¸ï¸ åœæ­¢æ’­æ”¾" : "ğŸµ æµ‹è¯•éŸ³é¢‘"}</span>
            </button>
            <span className={styles.settingStatus}>æ¨¡æ‹Ÿé¢è¯•å®˜æé—®</span>
          </div>
        </div>

        {/* æš‚åœæ¢å¤æŒ‰é’® */}
        <button
          onClick={togglePauseCommit}
          className={`${styles.button} ${styles.pauseButton} ${
            isPaused ? styles.paused : ""
          }`}
        >
          <span>{isPaused ? "â–¶ï¸ æ¢å¤ç›‘å¬" : "â¸ï¸ æš‚åœç›‘å¬"}</span>
        </button>

        <button
          onClick={stopRecognition}
          className={`${styles.button} ${styles.stopButton}`}
        >
          <StopIcon />
          <span>ç»“æŸé¢è¯•</span>
        </button>

        <button
          onClick={resetTranscript}
          className={`${styles.button} ${styles.clearButton}`}
        >
          <span>ğŸ—‘ï¸ æ¸…ç©º</span>
        </button>
      </div>

      {/* éšè—çš„æµ‹è¯•éŸ³é¢‘å…ƒç´  */}
      <audio
        ref={testAudioRef}
        src="/mock_interviewer.mp3"
        onEnded={handleTestAudioEnded}
        style={{ display: 'none' }}
      />
    </div>
  );
};

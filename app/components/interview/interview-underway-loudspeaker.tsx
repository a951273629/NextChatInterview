import React, { useRef, useState, useEffect } from "react";
import StopIcon from "@/app/icons/pause.svg";
import styles from "./interview-underway-loudspeaker.module.scss";
import {
  AzureSpeechRecognizer,
  getAzureSpeechConfig,
  isAzureSpeechAvailable,
} from "@/app/components/interview/azureSpeech";
import { SyncMode } from "@/app/types/websocket-sync";
import { useWebSocketSync } from "@/app/hooks/useWebSocketSync";
import { nanoid } from "nanoid";

// æ¶ˆæ¯ç±»å‹æ¥å£
interface Message {
  id: string;
  text: string;
  timestamp: number;
}

interface InterviewUnderwayLoudspeakerProps {
  // æ§åˆ¶çŠ¶æ€
  visible: boolean;
  recognitionLanguage: string;

  // å›è°ƒå‡½æ•°
  onTextUpdate: (text: string) => void;
  submitMessage: (text: string) => void;
  onStop: () => void;

  // å¯é€‰ï¼šé»˜è®¤è‡ªåŠ¨æäº¤çŠ¶æ€ï¼ˆæ‰¬å£°å™¨æ¨¡å¼ä¸‹é»˜è®¤å¼€å¯ï¼‰
  defaultAutoSubmit?: boolean;

  // åª’ä½“æµç›¸å…³props
  mediaStream: MediaStream | null;
  //   audioContext: AudioContext | null;
  onRequestPermission: () => Promise<void>;

  // åŒæ­¥åŠŸèƒ½ç›¸å…³props
  syncEnabled?: boolean;
  syncMode?: SyncMode;
  activationKey?: string;

  // ç§»åŠ¨ç«¯ç›¸å…³
  onMinimize?: () => void;
  isMobile?: boolean;

  // æ¶ˆæ¯ç®¡ç†
  messages?: Message[];
  onAddMessage?: (text: string) => void;
}

export const InterviewUnderwayLoudspeaker: React.FC<
  InterviewUnderwayLoudspeakerProps
> = ({
  visible,
  recognitionLanguage,
  onTextUpdate,
  submitMessage,
  onStop,
  defaultAutoSubmit = false,
  mediaStream,
  //   audioContext,
  onRequestPermission,
  syncEnabled = false,
  syncMode = SyncMode.SENDER,
  activationKey,
  onMinimize,
  isMobile = false,
  messages = [],
  onAddMessage,
}) => {
  // è¯­éŸ³è¯†åˆ«ç›¸å…³çŠ¶æ€
  const [transcript, setTranscript] = useState("");
  const [listening, setListening] = useState(false);
  const [browserSupportsApi, setBrowserSupportsApi] = useState(true);
  const [audioAvailable, setAudioAvailable] = useState(false);
  const transcriptRef = useRef(transcript);

  // Azure Speech è¯†åˆ«å™¨å¼•ç”¨
  const azureSpeechRecognizerRef = useRef<AzureSpeechRecognizer | null>(null);

  // æ§åˆ¶çŠ¶æ€
  const [isPaused, setIsPaused] = useState(false);
  const [isAutoSubmit, setIsAutoSubmit] = useState(defaultAutoSubmit);
  const [showTooltip, setShowTooltip] = useState(true);

  // æ¶ˆæ¯ç›¸å…³ - ç§»é™¤å†…éƒ¨çŠ¶æ€ï¼Œä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„
  // const [messages, setMessages] = useState<Message[]>([]);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const lastSubmittedTextRef = useRef("");
  const autoSubmitTimerRef = useRef<NodeJS.Timeout | null>(null);

  // WebSocket åŒæ­¥åŠŸèƒ½
  const webSocketSync = useWebSocketSync({
    activationKey: activationKey || "default_key",
    mode: syncMode,
    enabled: syncEnabled && visible,
    onSpeechRecognition: (data) => {
      // æ¥æ”¶ç«¯å¤„ç†é€»è¾‘ï¼šè‡ªåŠ¨æäº¤æ¥æ”¶åˆ°çš„è¯­éŸ³è¯†åˆ«ç»“æœ
      if (syncMode === SyncMode.RECEIVER) {
        console.log("ğŸ¯ æ¥æ”¶åˆ°åŒæ­¥çš„è¯­éŸ³è¯†åˆ«ç»“æœ:", data);
        // ç›´æ¥æäº¤æ¶ˆæ¯ï¼Œä¸ç»è¿‡æœ¬åœ°è¯†åˆ«æµç¨‹
        submitMessage(data.text);
        // å¯é€‰ï¼šä¹Ÿæ·»åŠ åˆ°æ¶ˆæ¯å†å²
        onAddMessage?.(data.text);
      }
    },
  });

  // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
  useEffect(() => {
    const checkBrowserSupport = () => {
      const hasGetDisplayMedia = !!(
        navigator.mediaDevices && navigator.mediaDevices.getDisplayMedia
      );
      const hasAudioContext = !!(
        window.AudioContext || window.webkitAudioContext
      );
      const hasAzureSpeech = isAzureSpeechAvailable();

      setBrowserSupportsApi(
        hasGetDisplayMedia && hasAudioContext && hasAzureSpeech,
      );

      if (!hasAzureSpeech) {
        console.warn("Azure Speech SDK ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®");
      }
    };

    checkBrowserSupport();
  }, []);

  // åˆå§‹åŒ– Azure Speech è¯†åˆ«å™¨
  const initializeAzureSpeechRecognizer = () => {
    try {
      if (!mediaStream) {
        throw new Error("MediaStream æœªå‡†å¤‡å°±ç»ª");
      }

      console.log("ğŸ”§ å‡†å¤‡åˆå§‹åŒ– Azure Speech è¯†åˆ«å™¨...");
      const config = getAzureSpeechConfig();
      // æ ¹æ®è¯†åˆ«è¯­è¨€è®¾ç½®é…ç½®
      config.language = recognitionLanguage;

      const recognizer = new AzureSpeechRecognizer(config);

      // è®¾ç½®éŸ³é¢‘æµï¼ˆç°åœ¨æ˜¯åŒæ­¥æ–¹æ³•ï¼‰
      recognizer.createAudioConfigFromStream(mediaStream);

      azureSpeechRecognizerRef.current = recognizer;

      return recognizer;
    } catch (error) {
      console.error("âŒ åˆå§‹åŒ– Azure Speech è¯†åˆ«å™¨å¤±è´¥:", error);
      throw error;
    }
  };

  // å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼ˆä½¿ç”¨ Azure Speech SDKï¼‰
  const startSpeechRecognition = () => {
    if (!mediaStream) {
      console.log("âš ï¸ åª’ä½“æµæœªå‡†å¤‡å°±ç»ªï¼Œè¯·å…ˆè·å–å½•å±æƒé™");
      return;
    }

    try {
      console.log("ğŸš€ å¼€å§‹ Azure è¯­éŸ³è¯†åˆ«...");

      // åˆå§‹åŒ– Azure Speech è¯†åˆ«å™¨
      const recognizer = initializeAzureSpeechRecognizer();

      // å¼€å§‹è¿ç»­è¯†åˆ«
      recognizer.startContinuousRecognition(
        // è¯†åˆ«ç»“æœå›è°ƒ
        (text: string, isFinal: boolean) => {
          console.log(
            `ğŸ¯ Azure è¯†åˆ«ç»“æœ (${isFinal ? "âœ…æœ€ç»ˆ" : "ğŸ”„ä¸­é—´"}):`,
            text,
          );
          setTranscript(text);
          transcriptRef.current = text;
          onTextUpdate(text);

          // å¦‚æœå¯ç”¨åŒæ­¥åŠŸèƒ½ä¸”ä¸ºå‘é€ç«¯ï¼Œåˆ™å‘é€è¯†åˆ«ç»“æœ
          if (
            syncEnabled &&
            syncMode === SyncMode.SENDER &&
            isFinal &&
            text.trim()
          ) {
            console.log("ğŸ“¤ å‘é€ç«¯æ¨¡å¼ï¼šé€šè¿‡WebSocketå‘é€è¯­éŸ³è¯†åˆ«ç»“æœ");
            webSocketSync.sendSpeechRecognition({
              text: text.trim(),
              isFinal,
              language: recognitionLanguage,
              sessionId: nanoid(),
            });
          }
        },
        // é”™è¯¯å›è°ƒ
        (error: string) => {
          console.error("âŒ Azure è¯­éŸ³è¯†åˆ«é”™è¯¯:", error);
          setListening(false);
          setAudioAvailable(false);
        },
        // ç»“æŸå›è°ƒ
        () => {
          console.log("ğŸ Azure è¯­éŸ³è¯†åˆ«ç»“æŸ");
          // å¦‚æœåº”è¯¥ç»§ç»­ç›‘å¬ä½†è¯†åˆ«ç»“æŸäº†ï¼Œé‡æ–°å¯åŠ¨
          if (visible && !isPaused && audioAvailable && mediaStream) {
            setTimeout(() => {
              console.log("ğŸ”„ é‡æ–°å¯åŠ¨è¯­éŸ³è¯†åˆ«...");
              startSpeechRecognition();
            }, 1000);
          } else {
            setListening(false);
          }
        },
      );

      setListening(true);
      setAudioAvailable(true);
    } catch (error: any) {
      console.error("âŒ å¯åŠ¨ Azure è¯­éŸ³è¯†åˆ«å¤±è´¥:", error);
      setAudioAvailable(false);
      setListening(false);
    }
  };

  // åœæ­¢è¯­éŸ³è¯†åˆ«
  const stopSpeechRecognition = () => {
    try {
      // åœæ­¢ Azure Speech è¯†åˆ«å™¨
      if (azureSpeechRecognizerRef.current) {
        azureSpeechRecognizerRef.current.stopRecognition();
        azureSpeechRecognizerRef.current.dispose();
        azureSpeechRecognizerRef.current = null;
      }

      setListening(false);
      setAudioAvailable(false);
    } catch (error) {
      console.error("åœæ­¢ Azure è¯­éŸ³è¯†åˆ«å¤±è´¥:", error);
    }
  };

  // é‡ç½®è½¬å½•æ–‡æœ¬
  const resetTranscript = () => {
    setTranscript("");
    transcriptRef.current = "";
    onTextUpdate("");
  };

  // å°†transcriptæ›´æ–°åˆ°çˆ¶ç»„ä»¶
  useEffect(() => {
    transcriptRef.current = transcript;
    onTextUpdate(transcript);
  }, [transcript, onTextUpdate]);

  // æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  };

  // æ¯å½“æ¶ˆæ¯åˆ—è¡¨æ›´æ–°æ—¶ï¼Œæ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    scrollToBottom();
  }, [messages]);



  // æ¶ˆæ¯ç‚¹å‡»å¤„ç†å‡½æ•°
  const handleMessageClick = (messageText: string) => {
    console.log("æ¶ˆæ¯è¢«ç‚¹å‡»:", messageText);
    submitMessage(messageText);
    
    // åœ¨ç§»åŠ¨ç«¯æ¨¡å¼ä¸‹ï¼Œç‚¹å‡»æ¶ˆæ¯åæœ€å°åŒ–é¡µé¢
    if (isMobile && onMinimize) {
      onMinimize();
    }
  };

  // å½“ç»„ä»¶å¯è§ä¸”æœªæš‚åœæ—¶å¼€å§‹éŸ³é¢‘æ•è·
  useEffect(() => {
    if (visible && !isPaused && browserSupportsApi && mediaStream) {
      console.log("useEffect: å¼€å§‹è¯­éŸ³è¯†åˆ«");
      startSpeechRecognition();
    } else {
      console.log("useEffect: åœæ­¢è¯­éŸ³è¯†åˆ«");
      stopSpeechRecognition();
    }

    return () => {
      // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
      stopSpeechRecognition();
    };
  }, [visible, isPaused, browserSupportsApi, mediaStream]);

  // è‡ªåŠ¨æäº¤æ‰¬å£°å™¨è¯­éŸ³ï¼ˆæ‰¬å£°å™¨æ¨¡å¼ä¸‹æ‰€æœ‰éŸ³é¢‘éƒ½è¢«è§†ä¸ºé¢è¯•å®˜éŸ³é¢‘ï¼‰
  useEffect(() => {
    // æ¸…é™¤ä¹‹å‰çš„è®¡æ—¶å™¨
    if (autoSubmitTimerRef.current) {
      clearTimeout(autoSubmitTimerRef.current);
      autoSubmitTimerRef.current = null;
    }

    // å¦‚æœæœ‰æ–‡æœ¬å†…å®¹
    if (transcript && transcript.trim() !== "") {
      // è®¾ç½®ä¸€ä¸ªçŸ­æš‚çš„å»¶è¿Ÿï¼Œç¡®ä¿æ”¶é›†åˆ°å®Œæ•´çš„å¥å­
      autoSubmitTimerRef.current = setTimeout(() => {
        // åªæœ‰å½“transcriptæ²¡æœ‰å˜åŒ–æ—¶æ‰å¤„ç†ï¼Œé¿å…å¥å­è¿˜åœ¨å½¢æˆè¿‡ç¨‹ä¸­å°±å¤„ç†
        if (transcript === transcriptRef.current) {
          // æ‰¬å£°å™¨æ¨¡å¼ä¸‹ï¼Œæ‰€æœ‰è¯­éŸ³éƒ½æ¥è‡ªç³»ç»ŸéŸ³é¢‘
          if (transcript !== lastSubmittedTextRef.current) {
            console.log("æ£€æµ‹åˆ°æ‰¬å£°å™¨éŸ³é¢‘ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯å†å²:", transcript);
            onAddMessage?.(transcript); // ç®€åŒ–è°ƒç”¨ï¼Œä¸éœ€è¦ä¼ é€’è¯´è¯è€…æ ‡è¯†
            lastSubmittedTextRef.current = transcript;
            resetTranscript();

            // å¦‚æœå¯ç”¨åŒæ­¥åŠŸèƒ½ä¸”ä¸ºå‘é€ç«¯ï¼Œä¸è¿›è¡Œæœ¬åœ°æäº¤ï¼Œåªé€šè¿‡WebSocketå‘é€
            if (syncEnabled && syncMode === SyncMode.SENDER) {
              console.log(
                "ğŸ“¤ å‘é€ç«¯æ¨¡å¼ï¼šè¯­éŸ³å·²é€šè¿‡WebSocketå‘é€ï¼Œè·³è¿‡æœ¬åœ°æäº¤",
              );
            } else if (isAutoSubmit) {
              // æ™®é€šæ¨¡å¼æˆ–æ¥æ”¶ç«¯æ¨¡å¼ä¸‹çš„æœ¬åœ°è‡ªåŠ¨æäº¤
              console.log("è‡ªåŠ¨æäº¤æ‰¬å£°å™¨è¯­éŸ³:", transcript);
              submitMessage(transcript);
            }
          }
        }
      }, 1800); // 1.8ç§’å»¶è¿Ÿ
    }

    return () => {
      if (autoSubmitTimerRef.current) {
        clearTimeout(autoSubmitTimerRef.current);
      }
    };
  }, [transcript, submitMessage, isAutoSubmit, syncEnabled, syncMode]);

  // æš‚åœ/æ¢å¤åŠŸèƒ½
  const togglePauseCommit = () => {
    if (!isPaused) {
      stopSpeechRecognition();
      resetTranscript();
    } else {
      startSpeechRecognition();
      resetTranscript();
    }
    setIsPaused(!isPaused);
  };

  // åœæ­¢è¯†åˆ«
  const stopRecognition = () => {
    try {
      stopSpeechRecognition();
      onStop();
    } catch (error) {
      console.error("åœæ­¢ç³»ç»ŸéŸ³é¢‘æ•è·å¤±è´¥:", error);
    }
  };

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      if (autoSubmitTimerRef.current) {
        clearTimeout(autoSubmitTimerRef.current);
      }
      stopSpeechRecognition();
    };
  }, []);

  return (
    <>
      {/* è¯­éŸ³è¯†åˆ«çŠ¶æ€æŒ‡ç¤ºå™¨ */}
      <div className={styles.statusIndicator}>
        <div
          className={`${styles.indicatorDot} ${
            listening ? styles.listening : styles.notListening
          }`}
        />
        <span className={styles.statusText}>
          {listening ? "æ­£åœ¨ç›‘å¬æ‰¬å£°å™¨..." : isPaused ? "å·²æš‚åœ" : "æœªç›‘å¬"}
        </span>

        {/* æ·»åŠ å¯ç‚¹å‡»æç¤ºæ°”æ³¡ */}
        {showTooltip && (
          <div className={styles.clickableTooltip}>
            <div className={styles.tooltipContent}>å•å‡»ä¸‹é¢çš„æ¶ˆæ¯è·å–å›ç­”</div>
            <button
              className={styles.tooltipCloseBtn}
              onClick={() => setShowTooltip(false)}
            >
              âœ•
            </button>
          </div>
        )}

        {/* æ‰¬å£°å™¨æ¨¡å¼æ ‡è¯† */}
        <div className={styles.modeStatus}>
          <span className={`${styles.identityIndicator} ${styles.interviewer}`}>
            æ‰¬å£°å™¨æ¨¡å¼
          </span>
          <span className={styles.audioSource}>éŸ³é¢‘æº: ç³»ç»Ÿæ‰¬å£°å™¨</span>

          {/* WebSocket åŒæ­¥çŠ¶æ€ */}
          {syncEnabled && (
            <div className={styles.syncStatus}>
              <span
                className={`${styles.syncIndicator} ${
                  webSocketSync.connectionStatus === "connected"
                    ? styles.connected
                    : webSocketSync.connectionStatus === "connecting"
                    ? styles.connecting
                    : styles.disconnected
                }`}
              >
                {webSocketSync.connectionStatus === "connected"
                  ? "ğŸŸ¢"
                  : webSocketSync.connectionStatus === "connecting"
                  ? "ğŸŸ¡"
                  : "ğŸ”´"}
              </span>
              <span className={styles.syncText}>
                {syncMode === SyncMode.SENDER ? "å‘é€ç«¯" : "æ¥æ”¶ç«¯"} -
                {webSocketSync.connectionStatus === "connected"
                  ? "å·²è¿æ¥"
                  : webSocketSync.connectionStatus === "connecting"
                  ? "è¿æ¥ä¸­"
                  : "æœªè¿æ¥"}
              </span>
              {webSocketSync.lastError && (
                <span className={styles.syncError}>
                  é”™è¯¯: {webSocketSync.lastError}
                </span>
              )}
            </div>
          )}
        </div>
      </div>

      {/* é”™è¯¯æç¤º */}
      {(!browserSupportsApi ||
        (!mediaStream && !audioAvailable && syncMode === SyncMode.SENDER)) && (
        <div className={styles.errorMessage}>
          {!browserSupportsApi ? (
            "æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒç³»ç»ŸéŸ³é¢‘æ•è·åŠŸèƒ½æˆ– Azure Speech SDK é…ç½®ç¼ºå¤±ï¼Œè¯·ä½¿ç”¨Chromeæµè§ˆå™¨å¹¶é…ç½® Azure å¯†é’¥"
          ) : !mediaStream ? (
            <div className={styles.permissionRequest}>
              <div>æœªè·å–å½•å±æƒé™ï¼Œæ— æ³•ç›‘å¬ç³»ç»ŸéŸ³é¢‘</div>
              <button
                className={styles.requestButton}
                onClick={onRequestPermission}
              >
                è·å–å½•å±æƒé™
              </button>
            </div>
          ) : (
            "æ— æ³•è®¿é—®ç³»ç»ŸéŸ³é¢‘ï¼Œè¯·æ£€æŸ¥å±å¹•å…±äº«æƒé™"
          )}
        </div>
      )}

      {/* æ¶ˆæ¯å†å²è®°å½•åŒºåŸŸ */}
      <div className={styles.messagesContainer}>
        {messages.map((message) => (
          <div
            key={message.id}
            className={`${styles.message} ${styles.interviewerMessage}`}
            onClick={() => handleMessageClick(message.text)}
          >
            {message.text}
          </div>
        ))}
        <div ref={messagesEndRef} />
      </div>

      {/* å½“å‰è¯†åˆ«æ–‡æœ¬æ˜¾ç¤ºåŒºåŸŸ */}
      {transcript && transcript.trim() !== "" && (
        <div
          className={`${styles.transcriptDisplay} ${styles.interviewerText}`}
        >
          <div className={styles.transcriptLabel}>å½“å‰è¯†åˆ«:</div>
          {transcript}
        </div>
      )}

      {/* æŒ‰é’®åŒºåŸŸ */}
      <div className={styles.buttonContainer}>
        {/* æ·»åŠ è‡ªåŠ¨æäº¤çš„å¼€å…³ */}
        <div className={styles.settingItem}>
          <div className={styles.settingLabel}>è‡ªåŠ¨æäº¤ï¼š</div>
          <div className={styles.settingControl}>
            <label className={styles.switch}>
              <input
                type="checkbox"
                checked={isAutoSubmit}
                onChange={() => setIsAutoSubmit(!isAutoSubmit)}
              />
              <span className={styles.slider}></span>
            </label>
            <span className={styles.settingStatus}>æ‰¬å£°å™¨æ¨¡å¼å¯ç”¨</span>
          </div>
        </div>

        {/* æš‚åœæ¢å¤æŒ‰é’® */}
        <button
          onClick={togglePauseCommit}
          className={`${styles.button} ${styles.pauseButton} ${
            isPaused ? styles.paused : ""
          }`}
        >
          <span>{isPaused ? "â–¶ï¸ æ¢å¤ç›‘å¬" : "â¸ï¸ æš‚åœç›‘å¬"}</span>
        </button>

        <button
          onClick={stopRecognition}
          className={`${styles.button} ${styles.stopButton}`}
        >
          <StopIcon />
          <span>ç»“æŸé¢è¯•</span>
        </button>

        <button
          onClick={resetTranscript}
          className={`${styles.button} ${styles.clearButton}`}
        >
          <span>ğŸ—‘ï¸ æ¸…ç©º</span>
        </button>
      </div>
    </>
  );
};

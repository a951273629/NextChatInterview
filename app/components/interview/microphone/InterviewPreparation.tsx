import React, { useCallback, useEffect, useRef, useState } from "react";
import styles from "./InterviewPreparation.module.scss";
import { toast } from "react-hot-toast";
import { safeLocalStorage } from "@/app/utils";
import { useNavigate } from "react-router-dom";
import { Path, NARROW_SIDEBAR_WIDTH } from "@/app/constant";
import { useAppConfig } from "@/app/store";
import {
  useInterviewLanguage,
  RecognitionLanguage,
  LANGUAGE_OPTIONS,
} from "@/app/hooks/useInterviewLanguage";
// å¯¼å…¥SVGå›¾æ ‡
import VoiceIcon from "@/app/icons/voice.svg";
import VoiceOffIcon from "@/app/icons/voice-off.svg";
import WIFI from "@/app/icons/wifi.svg";
import WIFIOff from "@/app/icons/wifi-off.svg";
import clsx from "clsx";

// import PowerIcon from "@/app/icons/power.svg";

const localStorage = safeLocalStorage();

interface InterviewPreparationProps {
  onStart: () => void;
  shouldNarrow: boolean;
  selectedMicId: string;
  onMicChange: (micId: string) => void;
}

// è®¾å¤‡çŠ¶æ€ç±»å‹
type DeviceStatus = "ready" | "error" | "unavailable" | "unauthorized";

// ç½‘ç»œçŠ¶æ€ç±»å‹
type NetworkStatus = "good" | "average" | "poor";

export const InterviewPreparation: React.FC<InterviewPreparationProps> = ({
  onStart,
  shouldNarrow,
  selectedMicId,
  onMicChange,
}) => {
  // ä½¿ç”¨è¯­è¨€Contextæ›¿ä»£æœ¬åœ°çŠ¶æ€
  const [recognitionLanguage, setRecognitionLanguage] = useInterviewLanguage();
  
  // è·å–åº”ç”¨é…ç½®ç”¨äºæ§åˆ¶ä¾§è¾¹æ å®½åº¦
  const config = useAppConfig();

  // éº¦å…‹é£çŠ¶æ€
  const [micStatus, setMicStatus] = useState<DeviceStatus>("unavailable");
  const [micVolume, setMicVolume] = useState<number>(0);

  // ç½‘ç»œçŠ¶æ€
  const [networkStatus, setNetworkStatus] = useState<NetworkStatus>("good");
  
  // éº¦å…‹é£è®¾å¤‡åˆ—è¡¨å’Œä¸‹æ‹‰èœå•çŠ¶æ€
  const [micList, setMicList] = useState<MediaDeviceInfo[]>([]);
  const [isMicListOpen, setIsMicListOpen] = useState(false);
  // éŸ³é¢‘æµå’Œåˆ†æå™¨å¼•ç”¨
  const audioStreamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameIdRef = useRef<number | NodeJS.Timeout | null>(null);

  // å¯¼èˆªhook
  const navigate = useNavigate();

  // åˆå§‹åŒ–æ—¶æ£€æµ‹è®¾å¤‡çŠ¶æ€
  useEffect(() => {
    console.log("å‡†å¤‡ç»„ä»¶å·²æŒ‚è½½ï¼Œå¼€å§‹è®¾å¤‡æ£€æŸ¥...");
    checkMicrophoneStatus();
    checkNetworkStatus();

    // ç»„ä»¶å¸è½½æ—¶æ¸…ç†èµ„æº
    return () => {
      cleanupAudioResources();
    };
  }, []);



  // ç›‘æµ‹éº¦å…‹é£éŸ³é‡
  const startVolumeMonitoring = useCallback(() => {
    if (!analyserRef.current || !audioContextRef.current) return;

    // é˜²å¾¡æ€§æ¸…ç†ï¼šç¡®ä¿åœ¨åˆ›å»ºæ–°å®šæ—¶å™¨ä¹‹å‰ï¼Œæ—§çš„å·²åœæ­¢
    if (animationFrameIdRef.current) {
      clearInterval(animationFrameIdRef.current);
      animationFrameIdRef.current = null;
    }

    const analyser = analyserRef.current;
    const audioContext = audioContextRef.current;
    
    // ä½¿ç”¨Float32Arrayè·å–æ—¶åŸŸæ•°æ®è¿›è¡Œæ­£ç¡®çš„éŸ³é‡è®¡ç®—
    const dataArray = new Float32Array(analyser.fftSize);

    // ä½¿ç”¨setIntervalæ¯500msæ›´æ–°ä¸€æ¬¡éŸ³é‡
    const intervalId = setInterval(() => {
      // æ£€æŸ¥AudioContextçŠ¶æ€
      if (audioContext.state === 'suspended') {
        console.log("AudioContextå¤„äºæš‚åœçŠ¶æ€ï¼Œå°è¯•æ¢å¤...");
        audioContext.resume().catch(err => {
          console.error("AudioContextæ¢å¤å¤±è´¥:", err);
        });
        return;
      }

      // è·å–æ—¶åŸŸæ•°æ®ï¼ˆç”¨äºéŸ³é‡è®¡ç®—ï¼‰
      analyser.getFloatTimeDomainData(dataArray);

      // è®¡ç®—RMSéŸ³é‡ï¼ˆå‡æ–¹æ ¹ï¼‰
      let sumSquares = 0.0;
      for (let i = 0; i < dataArray.length; i++) {
        sumSquares += dataArray[i] * dataArray[i];
      }
      const rms = Math.sqrt(sumSquares / dataArray.length);
      
      // è½¬æ¢åˆ°0-100èŒƒå›´ï¼Œå¹¶åº”ç”¨é€‚å½“çš„å¢ç›Š
      const volume = Math.min(100, Math.max(0, rms * 1000)); // å¢åŠ å¢ç›Šä½¿éŸ³é‡æ›´æ˜æ˜¾
      
      // console.log("éº¦å…‹é£éŸ³é‡ç›‘æµ‹:", { 
      //   rms: rms.toFixed(4), 
      //   volume: volume.toFixed(1),
      //   audioContextState: audioContext.state,
      //   dataArrayLength: dataArray.length
      // });
      
      setMicVolume(volume);
    }, 500);

    // ä¿å­˜intervalIdä»¥ä¾¿æ¸…ç†
    animationFrameIdRef.current = intervalId;
  }, []);

  // æ£€æµ‹éº¦å…‹é£çŠ¶æ€
  const checkMicrophoneStatus = useCallback(async () => {
    console.log("æ­£åœ¨æ£€æŸ¥éº¦å…‹é£çŠ¶æ€...");
    try {
      // æ„å»ºéŸ³é¢‘çº¦æŸï¼Œå¦‚æœæœ‰é€‰å®šçš„è®¾å¤‡IDå°±ä½¿ç”¨å®ƒ
      const audioConstraints: MediaStreamConstraints['audio'] = {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
        sampleRate: 16000,
      };
      
      if (selectedMicId) {
        audioConstraints.deviceId = { exact: selectedMicId };
      }
      
      // æ£€æŸ¥éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: audioConstraints
      });
      console.log("éº¦å…‹é£æƒé™å·²è·å–ï¼ŒéŸ³é¢‘æµå·²åˆ›å»º:", stream);
      audioStreamRef.current = stream;

      // æšä¸¾å¯ç”¨çš„éº¦å…‹é£è®¾å¤‡
      try {
        const devices = await navigator.mediaDevices.enumerateDevices();
        const mics = devices.filter(device => device.kind === 'audioinput' && device.deviceId !== 'default');
        console.log("æ£€æµ‹åˆ°çš„éº¦å…‹é£è®¾å¤‡:", mics);
        setMicList(mics);
        
        // å¦‚æœæ²¡æœ‰é€‰å®šçš„è®¾å¤‡ä¸”æœ‰å¯ç”¨è®¾å¤‡ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ª
        if (!selectedMicId && mics.length > 0) {
          onMicChange(mics[0].deviceId);
        }
      } catch (enumError) {
        console.error("æšä¸¾è®¾å¤‡å¤±è´¥:", enumError);
      }

      // åˆ›å»ºéŸ³é¢‘åˆ†æå™¨ç”¨äºéŸ³é‡æ£€æµ‹
      const audioContext = new (window.AudioContext ||
        (window as any).webkitAudioContext)();
      audioContextRef.current = audioContext;
      
      console.log("AudioContextåˆ›å»ºå®Œæˆï¼Œåˆå§‹çŠ¶æ€:", audioContext.state);

      // ç¡®ä¿AudioContextå¤„äºè¿è¡ŒçŠ¶æ€
      if (audioContext.state === 'suspended') {
        console.log("AudioContextå¤„äºæš‚åœçŠ¶æ€ï¼Œå°è¯•æ¿€æ´»...");
        try {
          await audioContext.resume();
          console.log("AudioContextå·²æ¿€æ´»ï¼Œå½“å‰çŠ¶æ€:", audioContext.state);
        } catch (resumeError) {
          console.error("AudioContextæ¿€æ´»å¤±è´¥:", resumeError);
        }
      }

      const analyser = audioContext.createAnalyser();
      // ä¼˜åŒ–åˆ†æå™¨é…ç½®
      analyser.fftSize = 2048; // å¢åŠ åˆ†è¾¨ç‡
      analyser.smoothingTimeConstant = 0.8; // æ·»åŠ å¹³æ»‘å¤„ç†
      analyserRef.current = analyser;

      const source = audioContext.createMediaStreamSource(stream);
      source.connect(analyser);
      
      console.log("éŸ³é¢‘åˆ†æå™¨é…ç½®å®Œæˆ:", {
        fftSize: analyser.fftSize,
        frequencyBinCount: analyser.frequencyBinCount,
        smoothingTimeConstant: analyser.smoothingTimeConstant
      });

      // éªŒè¯éŸ³é¢‘æµçŠ¶æ€
      const audioTracks = stream.getAudioTracks();
      if (audioTracks.length > 0) {
        console.log("éŸ³é¢‘è½¨é“ä¿¡æ¯:", {
          label: audioTracks[0].label,
          enabled: audioTracks[0].enabled,
          readyState: audioTracks[0].readyState,
          settings: audioTracks[0].getSettings()
        });
      }

      // å¼€å§‹ç›‘æµ‹éŸ³é‡
      startVolumeMonitoring();

      // æ·»åŠ éŸ³é‡æ£€æµ‹éªŒè¯æµ‹è¯•
      setTimeout(() => {
        if (analyserRef.current && audioContextRef.current) {
          console.log("ğŸ” æ‰§è¡ŒéŸ³é‡æ£€æµ‹éªŒè¯æµ‹è¯•...");
          const testDataArray = new Float32Array(analyserRef.current.fftSize);
          analyserRef.current.getFloatTimeDomainData(testDataArray);
          
          let hasNonZeroData = false;
          for (let i = 0; i < Math.min(100, testDataArray.length); i++) {
            if (Math.abs(testDataArray[i]) > 0.001) {
              hasNonZeroData = true;
              break;
            }
          }
          
          console.log("éŸ³é‡æ£€æµ‹éªŒè¯ç»“æœ:", {
            hasAudioData: hasNonZeroData,
            sampleDataRange: `${testDataArray[0].toFixed(4)} to ${testDataArray[Math.min(99, testDataArray.length-1)].toFixed(4)}`,
            contextState: audioContextRef.current.state
          });
          
          if (!hasNonZeroData) {
            console.warn("âš ï¸ è­¦å‘Šï¼šæ£€æµ‹åˆ°çš„éŸ³é¢‘æ•°æ®å…¨ä¸ºé›¶ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜");
          } else {
            console.log("âœ… éŸ³é¢‘æ•°æ®æ£€æµ‹æ­£å¸¸");
          }
        }
      }, 2000); // 2ç§’åè¿›è¡Œæµ‹è¯•

      setMicStatus("ready");
    } catch (error: any) {
      console.error("éº¦å…‹é£æ£€æµ‹å¤±è´¥:", error);

      // æ ¹æ®é”™è¯¯ç±»å‹è®¾ç½®ä¸åŒçš„çŠ¶æ€
      if (
        error.name === "NotAllowedError" ||
        error.name === "PermissionDeniedError"
      ) {
        setMicStatus("unauthorized");
      } else if (error.name === "NotFoundError") {
        setMicStatus("unavailable");
      } else {
        setMicStatus("error");
      }
    }
  }, [selectedMicId, onMicChange, startVolumeMonitoring]);

  // æ¸…ç†éŸ³é¢‘èµ„æº
  const cleanupAudioResources = () => {
    console.log("ğŸ§¹ æ¸…ç†éŸ³é¢‘èµ„æº...");
    
    if (animationFrameIdRef.current) {
      clearInterval(animationFrameIdRef.current);
      animationFrameIdRef.current = null;
      console.log("âœ… éŸ³é‡ç›‘æµ‹å®šæ—¶å™¨å·²æ¸…ç†");
    }

    if (audioContextRef.current) {
      // æ£€æŸ¥AudioContextçŠ¶æ€å†å…³é—­
      if (audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close().catch((err) => {
          console.error("å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡å¤±è´¥:", err);
        });
      }
      audioContextRef.current = null;
      console.log("âœ… AudioContextå·²å…³é—­");
    }

    if (audioStreamRef.current) {
      audioStreamRef.current.getTracks().forEach((track) => {
        track.stop();
        console.log("âœ… éŸ³é¢‘è½¨é“å·²åœæ­¢:", track.label || track.kind);
      });
      audioStreamRef.current = null;
      console.log("âœ… éŸ³é¢‘æµå·²é‡Šæ”¾");
    }

    // é‡ç½®åˆ†æå™¨å¼•ç”¨
    analyserRef.current = null;
    console.log("âœ… åˆ†æå™¨å¼•ç”¨å·²æ¸…ç†");
  };

  // æ£€æµ‹ç½‘ç»œçŠ¶æ€
  const checkNetworkStatus = () => {
    // ä½¿ç”¨ navigator.connection API (å¦‚æœå¯ç”¨)
    if ("connection" in navigator && navigator.connection) {
      const connection = (navigator as any).connection;

      // ç›‘å¬ç½‘ç»œå˜åŒ–
      connection.addEventListener("change", updateNetworkStatus);

      // åˆå§‹çŠ¶æ€æ›´æ–°
      updateNetworkStatus();
    } else {
      // å¦‚æœAPIä¸å¯ç”¨ï¼Œé»˜è®¤å‡è®¾ç½‘ç»œçŠ¶æ€è‰¯å¥½
      setNetworkStatus("good");
    }
  };

  // æ›´æ–°ç½‘ç»œçŠ¶æ€
  const updateNetworkStatus = () => {
    if (!("connection" in navigator)) return;

    const connection = (navigator as any).connection;

    if (connection.downlink >= 5) {
      setNetworkStatus("good");
    } else if (connection.downlink >= 2) {
      setNetworkStatus("average");
    } else {
      setNetworkStatus("poor");
    }
  };

  // å¤„ç†è¯­è¨€é€‰æ‹©
  const handleLanguageChange = (e: React.ChangeEvent<HTMLSelectElement>) => {
    setRecognitionLanguage(e.target.value as RecognitionLanguage);
  };

  // å¤„ç†éº¦å…‹é£è®¾å¤‡é€‰æ‹©
  const handleMicrophoneSelect = (deviceId: string) => {
    onMicChange(deviceId);
    setIsMicListOpen(false);
    // é‡æ–°æ£€æµ‹éº¦å…‹é£çŠ¶æ€
    setTimeout(() => {
      checkMicrophoneStatus();
    }, 100);
  };

  // åˆ‡æ¢éº¦å…‹é£é€‰æ‹©ä¸‹æ‹‰èœå•
  const toggleMicList = () => {
    setIsMicListOpen(!isMicListOpen);
  };

  // è·å–é€‰å®šéº¦å…‹é£çš„æ˜¾ç¤ºåç§°
  const getSelectedMicName = () => {
    if (!selectedMicId) return "é»˜è®¤éº¦å…‹é£";
    const selectedMic = micList.find(mic => mic.deviceId === selectedMicId);
    return selectedMic?.label || "æœªçŸ¥è®¾å¤‡";
  };

  // å¼€å§‹é¢è¯•ï¼Œä¼ é€’é€‰æ‹©çš„è¯­è¨€
  const handleStartInterview = () => {
    // è¿›å…¥é¢è¯•æ—¶å°†ä¾§è¾¹æ å®½åº¦è°ƒæ•´åˆ°æœ€å°
    config.update((config) => {
      config.sidebarWidth = NARROW_SIDEBAR_WIDTH;
    });
    onStart();
  };

  // è·å–éº¦å…‹é£çŠ¶æ€å¯¹åº”çš„å›¾æ ‡å’Œæ–‡å­—
  const getMicStatusInfo = () => {
    switch (micStatus) {
      case "ready":
        return {
          icon: <VoiceIcon />,
          text: "éº¦å…‹é£å·²è¿æ¥",
          colorClass: "status-success",
        };
      case "unauthorized":
        return {
          icon: <VoiceOffIcon />,
          text: "éº¦å…‹é£è®¿é—®è¢«æ‹’ç»ï¼Œè¯·æˆäºˆæƒé™",
          colorClass: "status-error",
        };
      case "unavailable":
        return {
          icon: <VoiceOffIcon />,
          text: "æœªæ£€æµ‹åˆ°éº¦å…‹é£è®¾å¤‡",
          colorClass: "status-error",
        };
      case "error":
        return {
          icon: <VoiceOffIcon />,
          text: "éº¦å…‹é£å‡ºç°æœªçŸ¥é”™è¯¯",
          colorClass: "status-error",
        };
      default:
        return {
          icon: <VoiceOffIcon />,
          text: "æ­£åœ¨æ£€æµ‹éº¦å…‹é£...",
          colorClass: "",
        };
    }
  };

  // è·å–ç½‘ç»œçŠ¶æ€å¯¹åº”çš„å›¾æ ‡å’Œæ–‡å­—
  const getNetworkStatusInfo = () => {
    switch (networkStatus) {
      case "good":
        return {
          icon: <WIFI />,
          text: "ç½‘ç»œè¿æ¥è‰¯å¥½",
          colorClass: "status-success",
        };
      case "average":
        return {
          icon: <WIFI />,
          text: "ç½‘ç»œè¿æ¥ä¸€èˆ¬",
          colorClass: "status-warning",
        };
      case "poor":
        return {
          icon: <WIFI />,
          text: "ç½‘ç»œè¿æ¥è¾ƒå·®ï¼Œå¯èƒ½å½±å“é¢è¯•",
          colorClass: "status-error",
        };
      default:
        return { icon: <WIFIOff />, text: "æ­£åœ¨æ£€æµ‹ç½‘ç»œ...", colorClass: "" };
    }
  };

  const micStatusInfo = getMicStatusInfo();
  const networkStatusInfo = getNetworkStatusInfo();

  return (
    <div
      className={clsx(styles["interview-prep-container"], {
        [styles["narrow-mode"]]: shouldNarrow,
      })}
    >
      <div className={styles["prep-header"]}>
        <p>è¯·ç¡®è®¤ä»¥ä¸‹è®¾ç½®åå¼€å§‹é¢è¯•</p>
      </div>

      <div className={styles["prep-main-content"]}>
        {/* ç®€å†ä¸Šä¼ ç»„ä»¶
        <div className={styles["prep-section"]}>
          <PreparationResumesUpload />
        </div> */}

        {/* è®¾å¤‡æ£€æŸ¥åŒºåŸŸ */}
        <div
          className={`${styles["prep-section"]} ${styles["device-check-section"]}`}
        >
          <h4 className={styles["section-title"]}>è®¾å¤‡æ£€æŸ¥</h4>

          {/* éº¦å…‹é£æ£€æŸ¥ */}
          <div className={styles["mic-select-container"]}>
            <div
              className={`${styles["device-status-item"]} ${
                styles[micStatusInfo.colorClass]
              }`}
              onClick={toggleMicList}
            >
              <div className={styles["status-icon"]}>{micStatusInfo.icon}</div>
              <div className={styles["status-info"]}>
                <div className={styles["status-text"]}>
                  {micStatus === "ready" ? getSelectedMicName() : micStatusInfo.text}
                </div>
                {micStatus === "ready" && (
                  <div className={styles["volume-indicator"]}>
                    <div className={styles["volume-bar-container"]}>
                      <div
                        className={styles["volume-bar"]}
                        style={{ width: `${micVolume}%` }}
                      ></div>
                    </div>
                  </div>
                )}
              </div>
              {micStatus === "ready" && micList.length > 1 && (
                <div className={styles["dropdown-arrow"]}>â–¼</div>
              )}
            </div>

            {/* éº¦å…‹é£è®¾å¤‡é€‰æ‹©ä¸‹æ‹‰èœå• */}
            {isMicListOpen && micStatus === "ready" && micList.length > 0 && (
              <div className={styles["mic-list"]}>
                {micList.map((mic) => (
                  <div
                    key={mic.deviceId}
                    className={`${styles["mic-option"]} ${
                      selectedMicId === mic.deviceId ? styles["selected"] : ""
                    }`}
                    onClick={() => handleMicrophoneSelect(mic.deviceId)}
                  >
                    {mic.label || "æœªçŸ¥è®¾å¤‡"}
                  </div>
                ))}
              </div>
            )}
          </div>

          {/* ç½‘ç»œæ£€æŸ¥ */}
          <div
            className={`${styles["device-status-item"]} ${
              styles[networkStatusInfo.colorClass]
            }`}
          >
            <div className={styles["status-icon"]}>
              {networkStatusInfo.icon}
            </div>
            <div className={styles["status-info"]}>
              <div className={styles["status-text"]}>
                {networkStatusInfo.text}
              </div>
            </div>
          </div>
        </div>

        {/* é¢è¯•è®¾ç½®åŒºåŸŸ */}
        <div
          className={`${styles["prep-section"]} ${styles["settings-section"]}`}
        >
          <h4 className={styles["section-title"]}>é¢è¯•è®¾ç½®</h4>

          {/* è¯­è¨€é€‰æ‹©è®¾ç½® */}
          <div className={styles["setting-item"]}>
            <div className={styles["setting-label"]}>è¯†åˆ«è¯­è¨€ï¼š</div>
            <div className={styles["setting-control"]}>
              <select
                className={styles["language-select"]}
                value={recognitionLanguage}
                onChange={handleLanguageChange}
              >
                {LANGUAGE_OPTIONS.map((option) => (
                  <option key={option.value} value={option.value}>
                    {option.label}
                  </option>
                ))}
              </select>
            </div>
          </div>
        </div>
      </div>

      {/* æ“ä½œæŒ‰é’®åŒºåŸŸ */}
      <div className={styles["prep-footer"]}>
        <button
          className={`${styles["start-button"]} ${
            micStatus !== "ready" ? styles["disabled"] : ""
          }`}
          onClick={handleStartInterview}
          disabled={micStatus !== "ready"}
        >
          å¼€å§‹é¢è¯•
        </button>
      </div>
    </div>
  );
};

export default InterviewPreparation;
